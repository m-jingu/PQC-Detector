#!/usr/bin/env python3
"""
PQC-Detector Summary Tool: Analyze CSV files from detector.py output

This tool reads CSV files generated by detector.py and calculates PQC-related statistics
including utilization rates, NamedGroups/CipherSuite distributions, and protocol analysis.

Features:
- Reads multiple CSV files from specified directory
- Calculates PQC utilization statistics
- Provides NamedGroups and CipherSuite frequency analysis
- Shows protocol distribution (QUIC/TLS/SSL/DTLS versions)
- Outputs human-readable formatted text
- Uses configurable mapping files for protocol versions and cipher suites
"""

import argparse
import csv
import os
import sys
from collections import Counter
from pathlib import Path
from typing import Dict, Generator, Tuple

import yaml


def load_config(config_path: Path) -> dict:
    """Load configuration from YAML file."""
    with config_path.open("r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}


def load_mappings(mappings_dir: Path) -> Tuple[Dict, Dict, Dict]:
    """Load supported groups, cipher suites, and protocol versions mappings from YAML files."""
    supported_groups_path = mappings_dir / "supported_groups.yaml"
    cipher_suites_path = mappings_dir / "cipher_suites.yaml"
    protocol_versions_path = mappings_dir / "protocol_versions.yaml"
    
    with supported_groups_path.open("r", encoding="utf-8") as f:
        supported_groups = yaml.safe_load(f) or {}
    
    with cipher_suites_path.open("r", encoding="utf-8") as f:
        cipher_suites = yaml.safe_load(f) or {}
    
    with protocol_versions_path.open("r", encoding="utf-8") as f:
        protocol_versions = yaml.safe_load(f) or {}
    
    return supported_groups, cipher_suites, protocol_versions


def read_csv_files(directory: Path) -> Generator[Dict, None, None]:
    """Read all *_server.csv files from directory and yield rows as dictionaries."""
    for csv_file in directory.rglob("*_server.csv"):
        try:
            with csv_file.open("r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    yield row
        except Exception as e:
            print(f"Warning: Failed to read {csv_file}: {e}", file=sys.stderr)
            continue


def normalize_group_id(group_id: str) -> int:
    """Normalize group ID to integer for mapping lookup."""
    if not group_id or group_id.strip() == "":
        return None
    
    group_id = group_id.strip()
    
    # If already hex format (0x...), convert to int
    if group_id.startswith("0x"):
        try:
            return int(group_id, 16)
        except ValueError:
            return None
    
    # If decimal number, return as int
    try:
        return int(group_id)
    except ValueError:
        return None


def normalize_cipher_id(cipher_id: str) -> int:
    """Normalize cipher suite ID to integer for mapping lookup."""
    if not cipher_id or cipher_id.strip() == "":
        return None
    
    cipher_id = cipher_id.strip()
    
    # If already hex format (0x...), convert to int
    if cipher_id.startswith("0x"):
        try:
            return int(cipher_id, 16)
        except ValueError:
            return None
    
    # If decimal number, return as int
    try:
        return int(cipher_id)
    except ValueError:
        return None


def normalize_protocol_name(proto: str, protocol_versions: Dict) -> str:
    """Convert protocol name to human-readable format using protocol versions mapping."""
    if not proto or proto.strip() == "":
        return proto
    
    proto = proto.strip()
    
    # If it's already a readable name, return as is
    if proto in ["QUIC", "TLSv1.2", "TLSv1.3", "TLS", "SSLv2", "SSLv3", "DTLSv1.0", "DTLSv1.2"]:
        return proto
    
    # Convert version hex to human-readable format using mapping
    if proto.startswith("0x"):
        try:
            version_hex = int(proto, 16)
            version_info = protocol_versions.get(version_hex)
            if version_info:
                return version_info.get("name", proto)
            else:
                return f"Unknown(0x{version_hex:04x})"
        except ValueError:
            return proto
    
    # If it's a decimal number, try to convert
    try:
        version_dec = int(proto)
        version_info = protocol_versions.get(version_dec)
        if version_info:
            return version_info.get("name", proto)
        else:
            return f"Unknown({version_dec})"
    except ValueError:
        return proto


def calculate_statistics(rows: Generator[Dict, None, None], 
                        supported_groups: Dict, 
                        cipher_suites: Dict,
                        protocol_versions: Dict) -> Dict:
    """Calculate statistics from CSV rows."""
    stats = {
        'total_packets': 0,
        'pqc_packets': 0,
        'group_counts': Counter(),
        'cipher_counts': Counter(),
        'protocol_counts': Counter(),
        'pqc_groups': set(),
        'group_names': {},
        'cipher_names': {}
    }
    
    for row in rows:
        stats['total_packets'] += 1
        
        # Protocol distribution
        proto = row.get('Proto', '').strip()
        if proto:
            stats['protocol_counts'][proto] += 1
        
        # KeyShareGroup analysis
        group_id = row.get('KeyShareGroup', '').strip()
        if group_id:
            normalized_id = normalize_group_id(group_id)
            if normalized_id is not None:
                group_info = supported_groups.get(normalized_id, {})
                group_name = group_info.get('name', f"Unknown({group_id})")
                is_pqc = group_info.get('is_pqc', False)
                
                stats['group_counts'][group_name] += 1
                stats['group_names'][group_name] = group_id
                
                if is_pqc:
                    stats['pqc_packets'] += 1
                    stats['pqc_groups'].add(group_name)
        
        # CipherSuite analysis
        cipher_id = row.get('CipherSuite', '').strip()
        if cipher_id:
            normalized_id = normalize_cipher_id(cipher_id)
            if normalized_id is not None:
                cipher_info = cipher_suites.get(normalized_id, {})
                cipher_name = cipher_info.get('name', f"Unknown({cipher_id})")
                
                stats['cipher_counts'][cipher_name] += 1
                stats['cipher_names'][cipher_name] = cipher_id
    
    return stats


def format_output(stats: Dict, protocol_versions: Dict) -> str:
    """Format statistics into human-readable text output."""
    output = []
    output.append("=== PQC Detection Summary ===")
    output.append("")
    
    # Basic statistics
    total = stats['total_packets']
    pqc = stats['pqc_packets']
    pqc_rate = (pqc / total * 100) if total > 0 else 0
    
    output.append(f"Total ServerHello packets: {total:,}")
    output.append(f"PQC packets: {pqc:,}")
    output.append(f"PQC utilization rate: {pqc_rate:.2f}%")
    output.append("")
    
    # PQC NamedGroups list
    if stats['pqc_groups']:
        output.append("PQC NamedGroups list:")
        for group in sorted(stats['pqc_groups']):
            output.append(f"  - {group}")
        output.append("")
    
    # PQC NamedGroups usage frequency (Top 10)
    pqc_group_counts = {name: count for name, count in stats['group_counts'].items() 
                       if name in stats['pqc_groups']}
    if pqc_group_counts:
        output.append("PQC NamedGroups usage frequency (Top 10):")
        for i, (group, count) in enumerate(sorted(pqc_group_counts.items(), 
                                                key=lambda x: x[1], reverse=True)[:10], 1):
            percentage = (count / total * 100) if total > 0 else 0
            output.append(f"  {i}. {group}: {count:,} ({percentage:.2f}%)")
        output.append("")
    
    # CipherSuite usage frequency (Top 10)
    if stats['cipher_counts']:
        output.append("CipherSuite usage frequency (Top 10):")
        for i, (cipher, count) in enumerate(stats['cipher_counts'].most_common(10), 1):
            percentage = (count / total * 100) if total > 0 else 0
            output.append(f"  {i}. {cipher}: {count:,} ({percentage:.2f}%)")
        output.append("")
    
    # Protocol distribution
    if stats['protocol_counts']:
        output.append("Protocol distribution:")
        for proto, count in sorted(stats['protocol_counts'].items(), 
                                 key=lambda x: x[1], reverse=True):
            percentage = (count / total * 100) if total > 0 else 0
            readable_proto = normalize_protocol_name(proto, protocol_versions)
            output.append(f"  - {readable_proto}: {count:,} ({percentage:.2f}%)")
    
    return "\n".join(output)


def parse_args(argv=None) -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Analyze CSV files from detector.py output and generate PQC statistics"
    )
    parser.add_argument(
        "directory", 
        type=str, 
        help="Directory containing *_server.csv files"
    )
    parser.add_argument(
        "--config", 
        type=str, 
        default="config.yaml", 
        help="Configuration file path"
    )
    return parser.parse_args(argv)


def main(argv=None) -> int:
    """Main entry point for the summary tool."""
    args = parse_args(argv)
    
    # Load configuration
    config_path = Path(args.config).resolve()
    if not config_path.exists():
        print(f"Error: Config file not found: {config_path}", file=sys.stderr)
        return 1
    
    config = load_config(config_path)
    
    # Get mappings directory from config
    mappings_dir = Path(config.get("summary", {}).get("mappings_dir", "mappings")).resolve()
    if not mappings_dir.exists():
        print(f"Error: Mappings directory not found: {mappings_dir}", file=sys.stderr)
        return 1
    
    # Load mappings
    try:
        supported_groups, cipher_suites, protocol_versions = load_mappings(mappings_dir)
    except Exception as e:
        print(f"Error: Failed to load mappings: {e}", file=sys.stderr)
        return 1
    
    # Process input directory
    input_dir = Path(args.directory).resolve()
    if not input_dir.exists():
        print(f"Error: Input directory not found: {input_dir}", file=sys.stderr)
        return 1
    
    # Read CSV files and calculate statistics
    try:
        rows = read_csv_files(input_dir)
        stats = calculate_statistics(rows, supported_groups, cipher_suites, protocol_versions)
        
        # Format and output results
        output = format_output(stats, protocol_versions)
        print(output)
        
    except Exception as e:
        print(f"Error: Failed to process files: {e}", file=sys.stderr)
        return 1
    
    return 0


if __name__ == "__main__":
    raise SystemExit(main())